le nom est : mikheev.pdf

le titre est : Periods, Capitalized Words, etc.


les auteur sont : tion: sentence boundary disambiguation, disambiguation of capitalized words in positions where capitalization is expected, and identification of abbreviations. As opposed to the two dominant 



l introduction est : 1. Introduction Disambiguation of sentence boundaries and normalization of capitalized words, as well as identification of abbreviations, however small in comparison to other tasks of text processing, are of primary importance in the developing of practical text- processing applications. These tasks are usually performed before actual “intelligent” text processing starts, and errors made at this stage are very likely to cause more errors at later stages and are therefore very dangerous. Disambiguation of capitalized words in mixed-case texts has received little atten- tion in the natural language processing and information retrieval communities, but in fact it plays an important role in many tasks. In mixed-case texts capitalized words usually denote proper names (names of organizations, locations, people, artifacts, etc.), but there are special positions in the text where capitalization is expected. Such manda- tory positions include the first word in a sentence, words in titles with all significant words capitalized or table entries, a capitalized word after a colon or open quote, and the first word in a list entry, among others. Capitalized words in these and some other positions present a case of ambiguity: they can stand for proper names, as in White later said . . . , or they can be just capitalized common words, as in White elephants are . . . . The disambiguation of capitalized words in ambiguous positions leads to the identification of proper names (or their derivatives), and in this article we will use these two terms and the term case normalization interchangeably. Church (1995, p. 294) studied, among other simple text normalization techniques, the effect of case normalization for different words and showed that “sometimes case variants refer to the same thing (hurricane and Hurricane), sometimes they refer to different things (continental and Continental) and sometimes they don’t refer to much of anything (e.g., anytime and Anytime).” Obviously these differences arise because some capitalized words stand for proper names (such as Continental, the name of an airline) and some do not. ∗ Institute for Communicating and Collaborative Systems, Division of Informatics, 2 Buccleuch Place, Edinburgh EH8 9LW, UK. E-mail: mikheev@cogsci.ed.ac.uk 290 Computational Linguistics Volume 28, Number 3 Proper names are the main concern of the named-entity recognition subtask (Chin- chor 1998) of information extraction. The main objective of this subtask is the identi- fication of proper names and also their classification into semantic categories (person, organization, location, etc.).1 There the disambiguation of the first word in a sentence (and in other ambiguous positions) is one of the central problems: about 20% of named entities occur in ambiguous positions. For instance, the word Black in the sentence- initial position can stand for a person’s surname but can also refer to the color. Even in multiword capitalized phrases, the first word can belong to the rest of the phrase or can be just an external modifier. In the sentence Daily, Mason and Partners lost their court case, it is clear that Daily, Mason and Partners is the name of a company. In the sentence Unfortunately, Mason and Partners lost their court case, the name of the company does not include the word Unfortunately, but the word Daily is just as common a word as Unfortunately. Identification of proper names is also important in machine translation, because usually proper names are transliterated (i.e., phonetically translated) rather than prop- erly (semantically) translated. In confidential texts, such as medical records, proper names must be identified and removed before making such texts available to people unauthorized to have access to personally identifiable information. And in general, most tasks that involve text analysis will benefit from the robust disambiguation of capitalized words into proper names and common words. Another important task of text normalization is sentence boundary disambigua- tion (SBD) or sentence splitting. Segmenting text into sentences is an important aspect in developing many applications: syntactic parsing, information extraction, machine translation, question answering, text alignment, document summarization, etc. Sen- tence splitting in most cases is a simple matter: a period, an exclamation mark, or a question mark usually signals a sentence boundary. In certain cases, however, a period denotes a decimal point or is a part of an abbreviation, and thus it does not necessarily signal a sentence boundary. Furthermore, an abbreviation itself can be the last token in a sentence in which case its period acts at the same time as part of this abbreviation and as the end-of-sentence indicator (fullstop). A detailed introduction to the SBD problem can be found in Palmer and Hearst (1997). The disambiguation of capitalized words and sentence boundaries presents a chicken-and-egg problem. If we know that a capitalized word that follows a period is a common word, we can safely assign such period as sentence terminal. On the other hand, if we know that a period is not sentence terminal, then we can conclude that the following capitalized word is a proper name. Another frequent source of ambiguity in end-of-sentence marking is introduced by abbreviations: if we know that the word that precedes a period is not an abbreviation, then almost certainly this period denotes a sentence boundary. If, however, this word is an abbreviation, then it is not that easy to make a clear decision. This problem is exacerbated by the fact that abbreviations do not form a closed set; that is, one can- not list all possible abbreviations. Moreover, abbreviations can coincide with regular words; for example, “in” can denote an abbreviation for “inches,” “no” can denote an abbreviation for “number,” and “bus” can denote an abbreviation for “business.” In this article we present a method that tackles sentence boundaries, capitalized words, and abbreviations in a uniform way through a document-centered approach. As opposed to the two dominant techniques of computing statistics about the words that surround potential sentence boundaries or writing specialized grammars, our ap- 1 In this article we are concerned only with the identification of proper names. 291 Mikheev Periods, Capitalized Words, etc. proach disambiguates capitalized words and abbreviations by considering suggestive local contexts and repetitions of individual words within a document. It then applies this information to identify sentence boundaries using a small set of rules. 

la conclusion est : (null)

ReferencesAberdeen, John S., John D. Burger, David S.Day, Lynette Hirschman, PatriciaRobinson, and Marc Vilain. 1995. “Mitre:Description of the alembic system usedfor MUC-6.” In Proceedings of the SixthMessage Understanding Conference (MUC-6),Columbia, Maryland, November. MorganKaufmann.Baldwin, Breck, Christine Doran, JeffreyReynar, Michael Niv, Bangalore Srinivas,and Mark Wasson. 1997. “EAGLE: Anextensible architecture for generallinguistic engineering.” In Proceedings ofComputer-Assisted Information Searching on316Internet (RIAO ’97), Montreal, June.Baum, Leonard E. and Ted Petrie. 1966.Statistical inference for probabilisticfunctions of finite Markov chains. Annalsof Mathematical Statistics 37:1559–1563.Bikel, Daniel, Scott Miller, RichardSchwartz, and Ralph Weischedel. 1997.“Nymble: A high performance learningname-finder.” In Proceedings of the FifthConference on Applied Natural LanguageProcessing (ANLP’97), pages 194–200.Washington, D.C., Morgan Kaufmann.Brill, Eric. 1995a. Transformation-basederror-driven learning and naturallanguage parsing: A case study inpart-of-speech tagging. ComputationalLinguistics 21(4):543–565.Brill, Eric. 1995b. “Unsupervised learning ofdisambiguation rules for part of speechtagging.” In David Yarovsky and KennethChurch, editors, Proceedings of the ThirdWorkshop on Very Large Corpora, pages1–13, Somerset, New Jersey. Associationfor Computational Linguistics.Burnage, Gavin. 1990. CELEX: A Guide forUsers. Centre for Lexical Information,Nijmegen, Netherlands.MikheevChinchor, Nancy. 1998. “Overview ofMUC-7.” In Seventh Message UnderstandingConference (MUC-7): Proceedings of aConference Held in Fairfax, April. MorganKaufmann.Church, Kenneth. 1988. “A stochastic partsprogram and noun-phrase parser forunrestricted text.” In Proceedings of theSecond ACL Conference on Applied NaturalLanguage Processing (ANLP’88), pages136–143, Austin, Texas.Church, Kenneth. 1995. “One term or two?”In SIGIR’95, Proceedings of the 18th AnnualInternational ACM SIGIR Conference onResearch and Development in InformationRetrieval, pages 310–318, Seattle,Washington, July. ACM Press.Clarkson, Philip and Anthony J. Robinson.1997. “Language model adaptation usingmixtures and an exponentially decayingcache.” In Proceedings IEEE InternationalConference on Speech and Signal Processing,Munich, Germany.Cucerzan, Silviu and David Yarowsky. 1999.“Language independent named entityrecognition combining morphological andcontextual evidence.” In Proceedings ofJoint SIGDAT Conference on EMNLP andVLC.Francis, W. Nelson and Henry Kucera. 1982.Frequency Analysis of English Usage: Lexiconand Grammar. Houghton Mifflin, NewYork.Gale, William, Kenneth Church, and DavidYarowsky. 1992. “One sense perdiscourse.” In Proceedings of the FourthDARPA Speech and Natural LanguageWorkshop, pages 233–237.Grefenstette, Gregory and Pasi Tapanainen.1994. “What is a word, what is asentence? Problems of tokenization.” InThe Proceedings of Third Conference onComputational Lexicography and TextResearch (COMPLEX’94), Budapest,Hungary.Krupka, George R. and Kevin Hausman.1998. Isoquest Inc.: Description of thenetowl extractor system as used forMUC-7. In Proceedings of the SeventhMessage Understanding Conference (MUC-7),Fairfax, VA. Morgan Kaufmann.Kuhn, Roland and Renato de Mori. 1998. Acache-based natural language model forspeech recognition. IEEE Transactions onPattern Analysis and Machine Intelligence12:570–583.Kupiec, Julian. 1992. Robust part-of-speechtagging using a hidden Markov model.Computer Speech and Language.Mani, Inderjeet and T. Richard MacMillan.1995. “Identifying unknown properPeriods, Capitalized Words, etc.names in newswire text.” In B. Boguraevand J. Pustejovsky, editors, CorpusProcessing for Lexical Acquisition. MIT Press,Cambridge, Massachusetts, pages 41–59.Marcus, Mitchell, Mary Ann Marcinkiewicz,and Beatrice Santorini. 1993. Building alarge annotated corpus of English: ThePenn treebank. Computational Linguistics19(2):313–329.Mikheev, Andrei. 1997. Automatic ruleinduction for unknown word guessing.Computational Linguistics 23(3):405–423.Mikheev, Andrei. 1999. A knowledge-freemethod for capitalized worddisambiguation. In Proceedings of the 37thConference of the Association forComputational Linguistics (ACL’99), pages159–168, University of Maryland, CollegePark.Mikheev, Andrei. 2000. “Tagging sentenceboundaries.” In Proceedings of the FirstMeeting of the North American Chapter of theComputational Linguistics (NAACL’2000),pages 264–271, Seattle, Washington.Morgan Kaufmann.Mikheev, Andrei, Clair Grover, and ColinMatheson. 1998. TTT: Text Tokenisation Tool.Language Technology Group, Universityof Edinburgh. Available athttp://www.ltg.ed.ac.uk/software/ttt/index.html.Mikheev, Andrei, Clair Grover, and MarcMoens. 1998. Description of the ltgsystem used for MUC-7. In SeventhMessage Understanding Conference(MUC–7): Proceedings of a Conference Held inFairfax, Virginia. Morgan Kaufmann.Mikheev, Andrei and Liubov Liubushkina.1995. Russian morphology: Anengineering approach. Natural LanguageEngineering 1(3):235–260.Palmer, David D. and Marti A. Hearst. 1994.“Adaptive sentence boundarydisambiguation.” In Proceedings of theFourth ACL Conference on Applied NaturalLanguage Processing (ANLP’94), pages78–83, Stuttgart, Germany, October.Morgan Kaufmann.Palmer, David D. and Marti A. Hearst. 1997.Adaptive multilingual sentence boundarydisambiguation. Computational Linguistics23(2):241–269.Park, Youngja and Roy J. Byrd. 2001.“Hybrid text mining for findingabbreviations and their definitions.” InProceedings of the Conference on EmpiricalMethods in Natural Language Processing(EMLP’01), pages 16–19, Washington,D.C. Morgan Kaufmann.Ratnaparkhi, Adwait. 1996. “A maximumentropy model for part-of-speech317Computational Linguisticstagging.” In Proceedings of Conference onEmpirical Methods in Natural LanguageProcessing, pages 133–142, University ofPennsylvania, Philadelphia.Reynar, Jeffrey C. and Adwait Ratnaparkhi.1997. “A maximum entropy approach toidentifying sentence boundaries.” InProceedings of the Fifth ACL Conference onApplied Natural Language Processing(ANLP’97), pages 16–19. MorganKaufmann.Riley, Michael D. 1989. “Some applicationsof tree-based modeling to speech and318Volume 28, Number 3language indexing.” In Proceedings of theDARPA Speech and Natural LanguageWorkshop, pages 339–352. MorganKaufmann.Yarowsky, David. 1993. “One sense percollocation.” In Proceedings of ARPAHuman Language Technology Workshop ’93,pages 266–271, Princeton, New Jersey.Yarowsky, David. 1995. “Unsupervisedword sense disambiguation rivalingsupervised methods.” In Meeting of theAssociation for Computational Linguistics(ACL’95), pages 189–196.

