le nom est : probabilistic_sentence_reduction.pdf

le titre est : Probabilistic Sentence Reduction Using Support Vector Machines 

les auteur sont :                  Minh Le Nguyen, Akira Shimazu, Susumu Horiguchi                           Bao Tu Ho and Masaru Fukushi 

Abstract This paper investigates a novel application of support vector machines (SVMs) for sentence reduction. We also propose a new probabilistic sentence reduction method based on support vector machine learning. Experimental results show that the proposed methods outperform earlier methods in term of sentence reduction performance.  1  

l introduction est : 1 Introduction The most popular methods of sentence reduc- tion for text summarization are corpus based methods. Jing (Jing 00) developed a method to remove extraneous phrases from sentences by using multiple sources of knowledge to de- cide which phrases could be removed. However, while this method exploits a simple model for sentence reduction by using statistics computed from a corpus, a better model can be obtained by using a learning approach. Knight and Marcu (Knight and Marcu 02) proposed a corpus based sentence reduction method using machine learning techniques. They discussed a noisy-channel based approach and a decision tree based approach to sentence reduction. Their algorithms provide the best way to scale up the full problem of sentence re- duction using available data. However, these al- gorithms require that the word order of a given sentence and its reduced sentence are the same. Nguyen and Horiguchi (Nguyen and Horiguchi 03) presented a new sentence reduction tech- nique based on a decision tree model without that constraint. They also indicated that se- mantic information is useful for sentence reduc- tion tasks. The major drawback of previous works on sentence reduction is that those methods are likely to output local optimal results, which may have lower accuracy. This problem is caused by the inherent sentence reduction model; that is, only a single reduced sentence can be obtained. As pointed out by Lin (Lin 03), the best sen- tence reduction output for a single sentence is not approximately best for text summarization. This means that “local optimal” refers to the best reduced output for a single sentence, while the best reduced output for the whole text is “global optimal”. Thus, it would be very valu- able if the sentence reduction task could gener- ate multiple reduced outputs and select the best one using the whole text document. However, such a sentence reduction method has not yet been proposed. Support Vector Machines (Vapnik 95), on the other hand, are strong learning methods in com- parison with decision tree learning and other learning methods (Sholkopf 97). The goal of this paper is to illustrate the potential of SVMs for enhancing the accuracy of sentence reduc- tion in comparison with previous work. Accord- ingly, we describe a novel deterministic method for sentence reduction using SVMs and a two- stage method using pairwise coupling (Hastie 98). To solve the problem of generating mul- tiple best outputs, we propose a probabilistic sentence reduction model, in which a variant of probabilistic SVMs using a two-stage method with pairwise coupling is discussed. The rest of this paper will be organized as follows: Section 2 introduces the Support Vec- tor Machines learning. Section 3 describes the previous work on sentence reduction and our deterministic sentence reduction using SVMs. We also discuss remaining problems of deter- ministic sentence reduction. Section 4 presents a probabilistic sentence reduction method using support vector machines to solve this problem. Section 5 discusses implementation and our ex- perimental results; Section 6 gives our conclu- sions and describes some problems that remain to be solved in the future. 

la conclusion est : (null)

ReferencesA. Borthwick, “A Maximum Entropy Approachto Named Entity Recognition”, Ph.D thesis, Computer Science Department, New YorkUniversity (1999).C.-C. Chang and C.-J. Lin,“LIBSVM: a library for support vector machines”, Software available athttp://www.csie.ntu.edu.tw/ cjlin/libsvm.H. Jing, “Sentence reduction for automatictext summarization”, In Proceedings of theFirst Annual Meeting of the North American Chapter of the Association for Computational Linguistics NAACL-2000.T.T. Hastie and R. Tibshirani, “Classificationby pairwise coupling”, The Annals of Statistics, 26(1): pp. 451-471, 1998.C.-W. Hsu and C.-J. Lin, “A comparison ofmethods for multi-class support vector machines”, IEEE Transactions on Neural Networks, 13, pp. 415-425, 2002.K. Knight and D. Marcu, “Summarization beyond sentence extraction: A Probabilistic approach to sentence compression”, ArtificialIntelligence 139: pp. 91-107, 2002.C.Y. Lin, “Improving Summarization Performance by Sentence Compression — A Pilot Study”, Proceedings of the Sixth International Workshop on Information Retrievalwith Asian Languages, pp.1-8, 2003.C. Macleod and R. Grishman, “COMMLEXsyntax Reference Manual”; Proteus Project,New York University (1995).M.L. Nguyen and S. Horiguchi, “A new sentencereduction based on Decision tree model”,Proceedings of 17th Pacific Asia Conferenceon Language, Information and Computation,pp. 290-297, 2003V. Vapnik, “The Natural of Statistical LearningTheory”, New York: Springer-Verlag, 1995.J. Platt,“ Probabilistic outputs for support vector machines and comparison to regularizedlikelihood methods,” in Advances in LargeMargin Classifiers, Cambridege, MA: MITPress, 2000.B. Scholkopf et al, “Comparing Support Vector Machines with Gausian Kernels to RadiusBasis Function Classifers”, IEEE Trans. Signal Procesing, 45, pp. 2758-2765, 1997.

